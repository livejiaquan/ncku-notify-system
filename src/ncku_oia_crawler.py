import os
import time
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import WebDriverException
from bs4 import BeautifulSoup
import logging
from config import load_config
from utils import setup_logger

class NCKUOIACrawler:
    def __init__(self):
        self.logger = setup_logger()
        self.project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        self.announcements_dir = os.path.join(self.project_root, 'data', 'announcements')
        self.filename = os.path.join(self.announcements_dir, 'announcements.txt')
        self._ensure_directories()
        self.max_retries = 3
        self.retry_delay = 5  # ç§’

    def _ensure_directories(self):
        """ç¢ºä¿å¿…è¦çš„ç›®éŒ„å­˜åœ¨"""
        try:
            if not os.path.exists(self.announcements_dir):
                os.makedirs(self.announcements_dir)
            if not os.path.exists(self.filename):
                with open(self.filename, 'w', encoding='utf-8') as f:
                    pass
        except OSError as e:
            self.logger.error(f"å‰µå»ºç›®éŒ„æˆ–æ–‡ä»¶æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            raise

    def _setup_driver(self):
        """è¨­ç½® Selenium WebDriver"""
        try:
            chrome_options = Options()
            chrome_options.add_argument("--headless")
            chrome_options.add_argument("--disable-gpu")
            chrome_options.add_argument("--no-sandbox")
            chrome_options.add_argument("--disable-dev-shm-usage")
            service = Service()
            return webdriver.Chrome(service=service, options=chrome_options)
        except Exception as e:
            self.logger.error(f"è¨­ç½®WebDriveræ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            raise

    def fetch_announcements(self, only_today=False):
        """çˆ¬å–å…¬å‘Šï¼ŒåŒ…å«é‡è©¦æ©Ÿåˆ¶"""
        for attempt in range(self.max_retries):
            try:
                return self._fetch_announcements_impl(only_today)
            except WebDriverException as e:
                if attempt == self.max_retries - 1:
                    self.logger.error(f"çˆ¬å–å¤±æ•—ï¼Œå·²é”åˆ°æœ€å¤§é‡è©¦æ¬¡æ•¸: {e}")
                    raise
                self.logger.warning(f"çˆ¬å–å¤±æ•—ï¼Œæ­£åœ¨é€²è¡Œç¬¬{attempt + 1}æ¬¡é‡è©¦")
                time.sleep(self.retry_delay)

    def _fetch_announcements_impl(self, only_today):
        """å¯¦éš›çš„çˆ¬å–é‚è¼¯"""
        driver = self._setup_driver()
        try:
            self.logger.info("é–‹å§‹çˆ¬å–æˆå¤§åœ‹éš›è™•ç¶²ç«™")
            driver.get('https://oia.ncku.edu.tw/?Lang=zh-tw')
            time.sleep(3)

            html = driver.page_source
            soup = BeautifulSoup(html, 'html.parser')
            announcements_section = soup.find('div', id='cmb_48_0')
            
            if not announcements_section:
                self.logger.warning("æœªæ‰¾åˆ°å…¬å‘Šå€å¡Š")
                return []

            current_date = datetime.now().strftime('%Y-%m-%d')
            announcements = []

            for item in announcements_section.find_all('div', class_='d-item d-title col-sm-12'):
                announcement = self._parse_announcement(item, current_date, only_today)
                if announcement:
                    announcements.append(announcement)

            self.logger.info(f"æˆåŠŸçˆ¬å–åˆ° {len(announcements)} æ¢å…¬å‘Š")
            return announcements
        finally:
            driver.quit()

    def _parse_announcement(self, item, current_date, only_today):
        """è§£æå–®æ¢å…¬å‘Š"""
        try:
            title = item.find('a').text.strip()
            link = item.find('a')['href'].strip()
            date = item.find('i', class_='mdate after').text.strip()

            if only_today and date != current_date:
                return None

            return {
                'title': title,
                'link': link,
                'date': date
            }
        except Exception as e:
            self.logger.warning(f"è§£æå…¬å‘Šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return None

    def get_new_announcements(self, announcements):
        """æª¢æŸ¥æ–°å…¬å‘Š"""
        saved_titles = self._read_saved_titles()
        return [ann for ann in announcements 
                if f"{ann['date']}: {ann['title']}" not in saved_titles]

    def _read_saved_titles(self):
        """è®€å–å·²ä¿å­˜çš„å…¬å‘Š"""
        with open(self.filename, 'r', encoding='utf-8') as f:
            return f.read().splitlines()

    def save_announcements(self, announcements):
        """ä¿å­˜æ–°å…¬å‘Š"""
        with open(self.filename, 'r', encoding='utf-8') as f:
            existing = f.readlines()

        with open(self.filename, 'w', encoding='utf-8') as f:
            for ann in announcements:
                f.write(f"{ann['date']}: {ann['title']}\n")
            f.writelines(existing)

    def format_email_content(self, announcements):
        """æ ¼å¼åŒ–éƒµä»¶å…§å®¹"""
        if not announcements:
            return None, None

        subject = "æˆå¤§åœ‹éš›äº‹å‹™è™•æ–°å…¬å‘Šé€šçŸ¥"
        body = "\nğŸ“¢ æˆå¤§åœ‹éš›äº‹å‹™è™•æ–°å…¬å‘Šï¼š\n\n"
        
        for ann in announcements:
            body += f"ğŸ”¹ {ann['date']} - {ann['title']}\n"
            body += f"ğŸ”— {ann['link']}\n\n"

        return subject, body 